[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kimberly Hochstedler. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hochstedler K (2022). COMBO: Correcting Misclassified Binary Outcomes Association Studies. R package version 0.0.0.9000.","code":"@Manual{,   title = {COMBO: Correcting Misclassified Binary Outcomes in Association Studies},   author = {Kimberly Hochstedler},   year = {2022},   note = {R package version 0.0.0.9000}, }"},{"path":"/index.html","id":"combo","dir":"","previous_headings":"","what":"Correcting Misclassified Binary Outcomes in Association Studies","title":"Correcting Misclassified Binary Outcomes in Association Studies","text":"COMBO: COrrecting Misclassified Binary Outcomes","code":""},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Correcting Misclassified Binary Outcomes in Association Studies","text":"COMBO provides set functions analysis regression models binary outcome misclassification. two main parts : Classification probability calculations Parameter estimation","code":""},{"path":"/index.html","id":"classification-probability-calculations","dir":"","previous_headings":"","what":"Classification probability calculations","title":"Correcting Misclassified Binary Outcomes in Association Studies","text":"package allows users compute probability latent true outcome conditional probability observing outcome given latent true outcome, based parameters estimated COMBO_EM COMBO_MCMC functions.","code":""},{"path":"/index.html","id":"parameter-estimation","dir":"","previous_headings":"","what":"Parameter estimation","title":"Correcting Misclassified Binary Outcomes in Association Studies","text":"Jointly estimate parameters true outcome observation mechanisms, respectively, binary outcome misclassification model using EM algorithm MCMC.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Correcting Misclassified Binary Outcomes in Association Studies","text":"","code":"# Install the development version from GitHub: # install.packages(\"devtools\") devtools::install_github(\"kimhochstedler/COMBO\")"},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 COMBO authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/reference/check_and_fix_chains.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Assumption and Fix Label Switching if Assumption is Broken for a List of MCMC Samples — check_and_fix_chains","title":"Check Assumption and Fix Label Switching if Assumption is Broken for a List of MCMC Samples — check_and_fix_chains","text":"Check Assumption Fix Label Switching Assumption Broken List MCMC Samples","code":""},{"path":"/reference/check_and_fix_chains.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Assumption and Fix Label Switching if Assumption is Broken for a List of MCMC Samples — check_and_fix_chains","text":"","code":"check_and_fix_chains(   n_chains,   chains_list,   pistarjj_matrix,   dim_x,   dim_z,   n_cat )"},{"path":"/reference/check_and_fix_chains.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Assumption and Fix Label Switching if Assumption is Broken for a List of MCMC Samples — check_and_fix_chains","text":"n_chains integer specifying number MCMC chains compute . chains_list numeric list containing samples n_chains MCMC chains. pistarjj_matrix numeric matrix average conditional probability \\(P(Y^* = j | Y = j, Z)\\) across subjects MCMC chain, obtained pistar_by_chain function. dim_x number columns design matrix true outcome mechanism, X. dim_z number columns design matrix observation mechanism, Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/check_and_fix_chains.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Assumption and Fix Label Switching if Assumption is Broken for a List of MCMC Samples — check_and_fix_chains","text":"check_and_fix_chains returns numeric list samples n_chains MCMC chains corrected label switching following assumption met: \\(P(Y^* = j | Y = j, Z) > 0.50 \\forall j\\).","code":""},{"path":"/reference/check_and_fix_chains.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Assumption and Fix Label Switching if Assumption is Broken for a List of MCMC Samples — check_and_fix_chains","text":"","code":"if (FALSE) { set.seed(123) n <- 100 x_mu <- 0 x_sigma <- 1 z_shape <- 1  beta <- matrix(c(1, 2), ncol = 1) gamma <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = beta, gamma = gamma) X <- my_data[[\"x_design_matrix\"]] Z <- my_data[[\"z_design_matrix\"]]  example_chain1 <- matrix(c(rnorm(n, mean = beta[1,1]),                            rnorm(n, mean = beta[2,1]),                            rnorm(n, mean = gamma[1,1]),                            rnorm(n, mean = gamma[1,2]),                            rnorm(n, mean = gamma[2,1]),                            rnorm(n, mean = gamma[2,2])),                            nrow = n, byrow = FALSE) colnames(example_chain1) <- c(\"beta[1,1]\", \"beta[1,2]\",                               \"gamma[1,1,1]\", \"gamma[1,2,1]\",                               \"gamma[1,1,2]\", \"gamma[1,2,2]\") example_chain2 <- matrix(c(rnorm(n, mean = beta[1,1]),                            rnorm(n, mean = beta[2,1]),                            rnorm(n, mean = gamma[1,1]),                            rnorm(n, mean = gamma[1,2]),                            rnorm(n, mean = gamma[2,1]),                            rnorm(n, mean = gamma[2,2])),                            nrow = n, byrow = FALSE) colnames(example_chain2) <- c(\"beta[1,1]\", \"beta[1,2]\",                               \"gamma[1,1,1]\", \"gamma[1,2,1]\",                               \"gamma[1,1,2]\", \"gamma[1,2,2]\") chains_list <- list(example_chain1, example_chain2) pistar_by_chain_matrix <- pistar_by_chain(n_chains = 2,                                           chains_list = chains_list,                                           Z = Z, n = n, n_cat = 2) fixed_chains <- check_and_fix_chains(n_chains = 2, chains_list = chains_list,                                      pistarjj_matrix = pistar_by_chain_matrix,                                      dim_x = ncol(X), dim_z = ncol(Z),                                      n_cat = 2)  pistar_by_chain_matrix chains_list[[1]][1:5,] fixed_chains[[1]][1:5,] chains_list[[2]][1:5,] fixed_chains[[2]][1:5,] }"},{"path":"/reference/COMBO_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Data to use in COMBO Functions — COMBO_data","title":"Generate Data to use in COMBO Functions — COMBO_data","text":"Generate Data use COMBO Functions","code":""},{"path":"/reference/COMBO_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Data to use in COMBO Functions — COMBO_data","text":"","code":"COMBO_data(sample_size, x_mu, x_sigma, z_shape, beta, gamma)"},{"path":"/reference/COMBO_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Data to use in COMBO Functions — COMBO_data","text":"sample_size integer specifying sample size generated data set. x_mu numeric value specifying mean x predictors generated Normal distribution. x_sigma positive numeric value specifying standard deviation x predictors generated Normal distribution. z_shape positive numeric value specifying shape parameter z predictors generated Gamma distribution. beta column matrix \\(\\beta\\) parameter values (intercept, slope) generate data true outcome mechanism. gamma numeric matrix \\(\\gamma\\) parameters generate data observation mechanism. matrix form, gamma_start matrix rows correspond intercept (row 1) slope (row 2) terms. gamma parameter matrix columns correspond true outcome categories \\(Y \\\\{1, 2\\}\\).","code":""},{"path":"/reference/COMBO_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Data to use in COMBO Functions — COMBO_data","text":"COMBO_data returns list generated data elements: obs_Y vector observed outcomes. true_Y vector true outcomes. obs_Y_matrix numeric matrix indicator variables (0, 1) observed outcome Y*. Rows matrix correspond subject. Columns matrix correspond observed outcome category. row contains exactly one 0 entry exactly one 1 entry. x vector generated predictor values true outcome mechanism, Normal distribution. z vector generated predictor values observation mechanism Gamma distribution. x_design_matrix design matrix x predictor. z_design_matrix design matrix z predictor.","code":""},{"path":"/reference/COMBO_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Data to use in COMBO Functions — COMBO_data","text":"","code":"set.seed(123) n <- 500 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = true_beta, gamma = true_gamma) table(my_data[[\"obs_Y\"]], my_data[[\"true_Y\"]]) #>     #>       1   2 #>   1 258  45 #>   2  63 134"},{"path":"/reference/COMBO_EM.html","id":null,"dir":"Reference","previous_headings":"","what":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","text":"Jointly estimate \\(\\beta\\) \\(\\gamma\\) parameters true outcome observation mechanisms, respectively, binary outcome misclassification model.","code":""},{"path":"/reference/COMBO_EM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","text":"","code":"COMBO_EM(   Ystar,   x_matrix,   z_matrix,   beta_start,   gamma_start,   tolerance = 1e-07,   max_em_iterations = 1500,   em_method = \"squarem\" )"},{"path":"/reference/COMBO_EM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","text":"Ystar numeric vector indicator variables (1, 2) observed outcome Y*. NA terms. reference category 2. x_matrix numeric matrix covariates true outcome mechanism. x_matrix contain intercept values NA. z_matrix numeric matrix covariates observation mechanism. z_matrix contain intercept values NA. beta_start numeric vector column matrix starting values \\(\\beta\\) parameters true outcome mechanism. number elements beta_start equal number columns x_matrix plus 1. gamma_start numeric vector matrix starting values \\(\\gamma\\) parameters observation mechanism. matrix form, gamma_start matrix rows correspond parameters Y* = 1 observed outcome, dimensions z_matrix plus 1, gamma parameter matrix columns correspond true outcome categories \\(Y \\\\{1, 2\\}\\). numeric vector gamma_start obtained concatenating gamma matrix, .e. gamma_start <- c(gamma_matrix). tolerance numeric value specifying stop estimation, based difference subsequent log-likelihood estimates. default 1e-7. max_em_iterations integer specifying maximum number iterations EM algorithm. default 1500. em_method character string specifying EM algorithm applied. Options \"em\", \"squarem\", \"pem\". default recommended option \"squarem\".","code":""},{"path":"/reference/COMBO_EM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","text":"COMBO_EM returns data frame containing four columns. first column, Parameter, represents unique parameter value row. next column contains parameter Estimates, followed standard error estimates, SE. final column, Convergence, reports whether algorithm converged given parameter estimate. Estimates provided binary misclassification model, well two additional cases. \"SAMBA\" parameter estimates R Package, SAMBA, uses EM algorithm estimate binary outcome misclassification model assumes perfect specificity. \"PSens\" parameter estimates estimated using EM algorithm binary outcome misclassification model assumes perfect sensitivitiy. \"Naive\" parameter estimates simple logistic regression Y* ~ X.","code":""},{"path":"/reference/COMBO_EM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","text":"Beesley, L. Mukherjee, B. (2020). Statistical inference association studies using electronic health records: Handling selection bias outcome misclassification. Biometrics, 78, 214-226.","code":""},{"path":"/reference/COMBO_EM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model — COMBO_EM","text":"","code":"set.seed(123) n <- 1000 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  x_matrix = matrix(rnorm(n, x_mu, x_sigma), ncol = 1) X = matrix(c(rep(1, n), x_matrix[,1]), ncol = 2, byrow = FALSE) z_matrix = matrix(rgamma(n, z_shape), ncol = 1) Z = matrix(c(rep(1, n), z_matrix[,1]), ncol = 2, byrow = FALSE)  exp_xb = exp(X %*% true_beta) pi_result = exp_xb[,1] / (exp_xb[,1] + 1) pi_matrix = matrix(c(pi_result, 1 - pi_result), ncol = 2, byrow = FALSE)  true_Y <- rep(NA, n) for(i in 1:n){     true_Y[i] = which(stats::rmultinom(1, 1, pi_matrix[i,]) == 1) }  exp_zg = exp(Z %*% true_gamma) pistar_denominator = matrix(c(1 + exp_zg[,1], 1 + exp_zg[,2]), ncol = 2, byrow = FALSE) pistar_result = exp_zg / pistar_denominator  pistar_matrix = matrix(c(pistar_result[,1], 1 - pistar_result[,1],                          pistar_result[,2], 1 - pistar_result[,2]),                        ncol = 2, byrow = FALSE)  obs_Y <- rep(NA, n) for(i in 1:n){     true_j = true_Y[i]     obs_Y[i] = which(rmultinom(1, 1,                      pistar_matrix[c(i, n + i),                                      true_j]) == 1)  }  Ystar <- obs_Y  starting_values <- rep(1,6) beta_start <- matrix(starting_values[1:2], ncol = 1) gamma_start <- matrix(starting_values[3:6], ncol = 2, nrow = 2, byrow = FALSE)  EM_results <- COMBO_EM(Ystar, x_matrix = x_matrix, z_matrix = z_matrix,                        beta_start = beta_start, gamma_start = gamma_start) #> Loading required package: doParallel #> Loading required package: foreach #> Loading required package: iterators #> Loading required package: parallel #> Loading required package: numDeriv #> Loading required package: quantreg #> Loading required package: SparseM #>  #> Attaching package: 'SparseM' #> The following object is masked from 'package:base': #>  #>     backsolve #>  #> Attaching package: 'turboEM' #> The following objects are masked from 'package:numDeriv': #>  #>     grad, hessian #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm! #> Warning: non-integer #successes in a binomial glm!  EM_results #>        Parameter    Estimates          SE Convergence #> 1          beta1   0.94890120          NA        TRUE #> 2          beta2  -2.35565018          NA        TRUE #> 3        gamma11   0.53773267          NA        TRUE #> 4        gamma21   0.94899526          NA        TRUE #> 5        gamma12  -0.03143942          NA        TRUE #> 6        gamma22  -1.42142132          NA        TRUE #> 7    SAMBA_beta1   1.02579269  0.29776853          NA #> 8    SAMBA_beta2  -1.13762209  0.20119894          NA #> 9  SAMBA_gamma11   1.22380033  0.30354598          NA #> 10 SAMBA_gamma21   0.57807251  0.35267049          NA #> 11   PSens_beta1   0.36958220  7.02366053          NA #> 12   PSens_beta2  -0.72231505  2.81551719          NA #> 13 PSens_gamma12  -0.75532783  3.28479253          NA #> 14 PSens_gamma22 -43.39974465 22.14360437          NA #> 15   naive_beta1   0.38315779  0.06811635        TRUE #> 16   naive_beta2  -0.71541393  0.07536077        TRUE"},{"path":"/reference/COMBO_MCMC.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC Estimation of the Binary Outcome Misclassification Model — COMBO_MCMC","title":"MCMC Estimation of the Binary Outcome Misclassification Model — COMBO_MCMC","text":"Jointly estimate \\(\\beta\\) \\(\\gamma\\) parameters true outcome observation mechanisms, respectively, binary outcome misclassification model.","code":""},{"path":"/reference/COMBO_MCMC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC Estimation of the Binary Outcome Misclassification Model — COMBO_MCMC","text":"","code":"COMBO_MCMC(   Ystar,   x,   z,   prior,   beta_prior_parameters,   gamma_prior_parameters,   number_MCMC_chains = 4,   MCMC_sample = 2000,   burn_in = 1000 )"},{"path":"/reference/COMBO_MCMC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC Estimation of the Binary Outcome Misclassification Model — COMBO_MCMC","text":"Ystar numeric vector indicator variables (1, 2) observed outcome Y*. reference category 2. x numeric matrix covariates true outcome mechanism. x contain intercept. z numeric matrix covariates observation mechanism. x_matrix contain intercept. prior character string specifying prior distribution \\(\\beta\\) \\(\\gamma\\) parameters. Options \"t\", \"uniform\", \"normal\", \"dexp\" (double Exponential, Weibull). beta_prior_parameters numeric list prior distribution parameters \\(\\beta\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", first element list contain matrix location, lower bound, mean, shape parameters, respectively, \\(\\beta\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", second element list contain matrix shape, upper bound, standard deviation, scale parameters, respectively, \\(\\beta\\) terms. prior distribution \"t\", third element list contain matrix degrees freedom \\(\\beta\\) terms. third list element empty prior distributions. matrices list dimensions n_cat X dim_x, elements n_cat row set NA. gamma_prior_parameters numeric list prior distribution parameters \\(\\gamma\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", first element list contain array location, lower bound, mean, shape parameters, respectively, \\(\\gamma\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", second element list contain array shape, upper bound, standard deviation, scale parameters, respectively, \\(\\gamma\\) terms. prior distribution \"t\", third element list contain array degrees freedom \\(\\gamma\\) terms. third list element empty prior distributions. arrays list dimensions n_cat X n_cat X dim_z, elements n_cat row set NA. number_MCMC_chains integer specifying number MCMC chains compute. default 4. MCMC_sample integer specifying number MCMC samples draw. default 2000. burn_in integer specifying number MCMC samples discard burn-period. default 1000.","code":""},{"path":"/reference/COMBO_MCMC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC Estimation of the Binary Outcome Misclassification Model — COMBO_MCMC","text":"COMBO_MCMC returns list posterior samples posterior means binary outcome misclassification model naive logistic regression observed outcome, Y*, predicted matrix x. list contains following components: posterior_sample_df data frame containing three columns. first column indicates chain sample taken, 1 number_MCMC_chains. second column specifies parameter associated given row. \\(\\beta\\) terms dimensions dim_x X n_cat. \\(\\gamma\\) terms dimensions n_cat X n_cat X dim_z, first index specifies observed outcome category second index specifies true outcome category. final column provides MCMC sample. posterior_means_df data frame containing three columns. first column specifies parameter associated given row. Parameters indexed posterior_sample_df. second column provides posterior mean computed across chains samples. final column provides posterior median computed across chains samples. naive_posterior_sample_df data frame containing three columns. first column indicates chain sample taken, 1 number_MCMC_chains. second column specifies parameter associated given row. Naive \\(\\beta\\) terms dimensions dim_x X n_cat. final column provides MCMC sample. naive_posterior_means_df data frame containing three columns. first column specifies naive parameter associated given row. Parameters indexed naive_posterior_sample_df. second column provides posterior mean computed across chains samples. final column provides posterior median computed across chains samples.","code":""},{"path":"/reference/COMBO_MCMC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC Estimation of the Binary Outcome Misclassification Model — COMBO_MCMC","text":"","code":"set.seed(123) n <- 1000 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  x_matrix = matrix(rnorm(n, x_mu, x_sigma), ncol = 1) X = matrix(c(rep(1, n), x_matrix[,1]), ncol = 2, byrow = FALSE) z_matrix = matrix(rgamma(n, z_shape), ncol = 1) Z = matrix(c(rep(1, n), z_matrix[,1]), ncol = 2, byrow = FALSE)  exp_xb = exp(X %*% true_beta) pi_result = exp_xb[,1] / (exp_xb[,1] + 1) pi_matrix = matrix(c(pi_result, 1 - pi_result), ncol = 2, byrow = FALSE)  true_Y <- rep(NA, n) for(i in 1:n){     true_Y[i] = which(stats::rmultinom(1, 1, pi_matrix[i,]) == 1) }  exp_zg = exp(Z %*% true_gamma) pistar_denominator = matrix(c(1 + exp_zg[,1], 1 + exp_zg[,2]), ncol = 2, byrow = FALSE) pistar_result = exp_zg / pistar_denominator  pistar_matrix = matrix(c(pistar_result[,1], 1 - pistar_result[,1],                          pistar_result[,2], 1 - pistar_result[,2]),                        ncol = 2, byrow = FALSE)  obs_Y <- rep(NA, n) for(i in 1:n){     true_j = true_Y[i]     obs_Y[i] = which(rmultinom(1, 1,                      pistar_matrix[c(i, n + i),                                      true_j]) == 1)  }  Ystar <- obs_Y  unif_lower_beta <- matrix(c(-5, -5, NA, NA), nrow = 2, byrow = TRUE) unif_upper_beta <- matrix(c(5, 5, NA, NA), nrow = 2, byrow = TRUE)  unif_lower_gamma <- array(data = c(-5, NA, -5, NA, -5, NA, -5, NA),                           dim = c(2,2,2)) unif_upper_gamma <- array(data = c(5, NA, 5, NA, 5, NA, 5, NA),                           dim = c(2,2,2))  beta_prior_parameters <- list(lower = unif_lower_beta, upper = unif_upper_beta) gamma_prior_parameters <- list(lower = unif_lower_gamma, upper = unif_upper_gamma)  MCMC_results <- COMBO_MCMC(Ystar, x = x_matrix, z = z_matrix,                            prior = \"uniform\",                            beta_prior_parameters = beta_prior_parameters,                            gamma_prior_parameters = gamma_prior_parameters,                            number_MCMC_chains = 2,                            MCMC_sample = 200, burn_in = 100) #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 1000 #>    Unobserved stochastic nodes: 6 #>    Total graph size: 35030 #>  #> Initializing model #>  #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 1000 #>    Unobserved stochastic nodes: 2 #>    Total graph size: 12013 #>  #> Initializing model #>  MCMC_results$posterior_means_df #> # A tibble: 6 × 3 #>   parameter    posterior_mean posterior_median #>   <fct>                 <dbl>            <dbl> #> 1 beta[1,1]            0.944            0.942  #> 2 beta[1,2]           -2.37            -2.37   #> 3 gamma[1,1,1]         0.537            0.544  #> 4 gamma[1,2,1]         0.0173           0.0243 #> 5 gamma[1,1,2]         1.02             0.976  #> 6 gamma[1,2,2]        -1.54            -1.55"},{"path":"/reference/em_function.html","id":null,"dir":"Reference","previous_headings":"","what":"EM-Algorithm Function for Estimation of the Misclassification Model — em_function","title":"EM-Algorithm Function for Estimation of the Misclassification Model — em_function","text":"EM-Algorithm Function Estimation Misclassification Model","code":""},{"path":"/reference/em_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM-Algorithm Function for Estimation of the Misclassification Model — em_function","text":"","code":"em_function(param_current, obs_Y_matrix, X, Z, sample_size, n_cat)"},{"path":"/reference/em_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM-Algorithm Function for Estimation of the Misclassification Model — em_function","text":"param_current numeric vector regression parameters, order \\(\\beta, \\gamma\\). \\(\\gamma\\) vector obtained matrix form. matrix form, gamma parameter matrix rows correspond parameters Y* = 1 observed outcome, dimensions Z. matrix form, gamma parameter matrix columns correspond true outcome categories \\(j = 1, \\dots,\\) n_cat. numeric vector gamma_v obtained concatenating gamma matrix, .e. gamma_v <- c(gamma_matrix). obs_Y_matrix numeric matrix indicator variables (0, 1) observed outcome Y*. Rows matrix correspond subject. Columns matrix correspond observed outcome category. row contain exactly one 0 entry exactly one 1 entry. X numeric design matrix true outcome mechanism. Z numeric design matrix observation mechanism. sample_size integer value specifying number observations sample. value equal number rows design matrix, X Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/em_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM-Algorithm Function for Estimation of the Misclassification Model — em_function","text":"em_function returns numeric vector updated parameter estimates one iteration EM-algorithm.","code":""},{"path":"/reference/em_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM-Algorithm Function for Estimation of the Misclassification Model — em_function","text":"","code":"if (FALSE) {  set.seed(123) n <- 1000 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = true_beta, gamma = true_gamma)  obs_Y_matrix = my_data[[\"obs_Y_matrix\"]] X = my_data[[\"x_design_matrix\"]] Z = my_data[[\"z_design_matrix\"]]  starting_values <- rnorm(6)  new_parameters <- em_function(starting_values,                               obs_Y_matrix = obs_Y_matrix,                               X = X, Z = Z,                               sample_size = n, n_cat = 2)  new_parameters }"},{"path":"/reference/expit.html","id":null,"dir":"Reference","previous_headings":"","what":"Expit function — expit","title":"Expit function — expit","text":"\\(\\frac{\\exp\\{x\\}}{1 + \\exp\\{x\\}}\\)","code":""},{"path":"/reference/expit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expit function — expit","text":"","code":"expit(x)"},{"path":"/reference/expit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expit function — expit","text":"x numeric value vector compute expit function .","code":""},{"path":"/reference/expit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expit function — expit","text":"expit returns result function \\(f(x) = \\frac{\\exp\\{x\\}}{1 + \\exp\\{x\\}}\\) given x.","code":""},{"path":"/reference/expit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expit function — expit","text":"","code":"if (FALSE) { x <- c(1, 2, 3)  expit(x)  exp(x) / (1 + exp(x)) }"},{"path":"/reference/jags_picker.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up a Binary Outcome Misclassification jags.model Object for a Given Prior — jags_picker","title":"Set up a Binary Outcome Misclassification jags.model Object for a Given Prior — jags_picker","text":"Set Binary Outcome Misclassification jags.model Object Given Prior","code":""},{"path":"/reference/jags_picker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up a Binary Outcome Misclassification jags.model Object for a Given Prior — jags_picker","text":"","code":"jags_picker(   prior,   sample_size,   dim_x,   dim_z,   n_cat,   Ystar,   X,   Z,   beta_prior_parameters,   gamma_prior_parameters,   number_MCMC_chains,   model_file )"},{"path":"/reference/jags_picker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up a Binary Outcome Misclassification jags.model Object for a Given Prior — jags_picker","text":"prior character string specifying prior distribution \\(\\beta\\) \\(\\gamma\\) parameters. Options \"t\", \"uniform\", \"normal\", \"dexp\" (double Exponential, Weibull). sample_size integer value specifying number observations sample. dim_x integer specifying number columns design matrix true outcome mechanism, X. dim_z integer specifying number columns design matrix observation mechanism, Z. n_cat integer specifying number categorical values true outcome, Y, observed outcome, Y* can take. Ystar numeric vector indicator variables (1, 2) observed outcome Y*. reference category 2. X numeric design matrix true outcome mechanism. Z numeric design matrix observation mechanism. beta_prior_parameters numeric list prior distribution parameters \\(\\beta\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", first element list contain matrix location, lower bound, mean, shape parameters, respectively, \\(\\beta\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", second element list contain matrix shape, upper bound, standard deviation, scale parameters, respectively, \\(\\beta\\) terms. prior distribution \"t\", third element list contain matrix degrees freedom \\(\\beta\\) terms. third list element empty prior distributions. matrices list dimensions dim_x X n_cat, elements n_cat column set NA. gamma_prior_parameters numeric list prior distribution parameters \\(\\gamma\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", first element list contain array location, lower bound, mean, shape parameters, respectively, \\(\\gamma\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", second element list contain array shape, upper bound, standard deviation, scale parameters, respectively, \\(\\gamma\\) terms. prior distribution \"t\", third element list contain array degrees freedom \\(\\gamma\\) terms. third list element empty prior distributions. arrays list dimensions n_cat X n_cat X dim_z, elements n_cat row set NA. number_MCMC_chains integer specifying number MCMC chains compute. model_file .BUG file used MCMC estimation rjags.","code":""},{"path":"/reference/jags_picker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up a Binary Outcome Misclassification jags.model Object for a Given Prior — jags_picker","text":"jags_picker returns jags.model object binay outcome misclassification model. object includes specified prior distribution, model, number chains, data.","code":""},{"path":"/reference/jags_picker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up a Binary Outcome Misclassification jags.model Object for a Given Prior — jags_picker","text":"","code":"if (FALSE) { set.seed(123) n <- 100 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = true_beta, gamma = true_gamma)  obs_Y = my_data[[\"obs_Y\"]] X = my_data[[\"x_design_matrix\"]] Z = my_data[[\"z_design_matrix\"]]  unif_lower_beta <- matrix(c(-5, -5, NA, NA), nrow = 2, byrow = TRUE) unif_upper_beta <- matrix(c(5, 5, NA, NA), nrow = 2, byrow = TRUE)  unif_lower_gamma <- array(data = c(-5, NA, -5, NA, -5, NA, -5, NA),                           dim = c(2,2,2)) unif_upper_gamma <- array(data = c(5, NA, 5, NA, 5, NA, 5, NA),                           dim = c(2,2,2))  beta_prior_parameters <- list(lower = unif_lower_beta, upper = unif_upper_beta) gamma_prior_parameters <- list(lower = unif_lower_gamma, upper = unif_upper_gamma)  modelstring = model_picker(prior = \"uniform\") temp_model_file = tempfile() tmps = file(temp_model_file, \"w\") cat(modelstring, file = tmps) close(tmps)  jags_model_object <- jags_picker(prior = \"uniform\",                                  sample_size = n,                                  dim_x = ncol(X), dim_z = ncol(Z),                                  n_cat = 2,                                  Ystar = obs_Y, X = X, Z = Z,                                  beta_prior_parameters = beta_prior_parameters,                                  gamma_prior_parameters = gamma_prior_parameters,                                  number_MCMC_chains = 1,                                  model_file = temp_model_file) }"},{"path":"/reference/label_switch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix Label Switching in MCMC Results from a Binary Outcome Misclassification Model — label_switch","title":"Fix Label Switching in MCMC Results from a Binary Outcome Misclassification Model — label_switch","text":"Fix Label Switching MCMC Results Binary Outcome Misclassification Model","code":""},{"path":"/reference/label_switch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix Label Switching in MCMC Results from a Binary Outcome Misclassification Model — label_switch","text":"","code":"label_switch(chain_matrix, dim_x, dim_z, n_cat)"},{"path":"/reference/label_switch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix Label Switching in MCMC Results from a Binary Outcome Misclassification Model — label_switch","text":"chain_matrix numeric matrix containing posterior samples parameters given MCMC chain. chain_matrix must named object (.e. parameter must named beta[j, p] gamma[k,j,p]). dim_x integer specifying number columns design matrix true outcome mechanism, X. dim_z integer specifying number columns design matrix observation mechanism, Z. n_cat integer specifying number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/label_switch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix Label Switching in MCMC Results from a Binary Outcome Misclassification Model — label_switch","text":"label_switch returns named matrix MCMC posterior samples parameters performing label switching according following pattern: \\(\\beta\\) terms multiplied -1, \\(\\gamma\\) terms \"swapped\" opposite j index.","code":""},{"path":"/reference/label_switch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fix Label Switching in MCMC Results from a Binary Outcome Misclassification Model — label_switch","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 x_mu <- 0 x_sigma <- 1 z_shape <- 1  beta <- matrix(c(1, 2), ncol = 1) gamma <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = beta, gamma = gamma)  obs_Y = my_data[[\"obs_Y\"]] X = my_data[[\"x_design_matrix\"]] Z = my_data[[\"z_design_matrix\"]]  example_chain1 <- matrix(c(rnorm(n, mean = beta[1,1]),                            rnorm(n, mean = beta[2,1]),                            rnorm(n, mean = gamma[1,1]),                            rnorm(n, mean = gamma[1,2]),                            rnorm(n, mean = gamma[2,1]),                            rnorm(n, mean = gamma[2,2])),                            nrow = n, byrow = FALSE) colnames(example_chain1) <- c(\"beta[1,1]\", \"beta[1,2]\",                               \"gamma[1,1,1]\", \"gamma[1,2,1]\",                               \"gamma[1,1,2]\", \"gamma[1,2,2]\")  label_switch_chain1 <- label_switch(example_chain1, ncol(X), ncol(Z), n_cat = 2)  head(example_chain1) head(label_switch_chain1) }"},{"path":"/reference/loglik.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected Complete Data Log-Likelihood Function for Estimation of the Misclassification Model — loglik","title":"Expected Complete Data Log-Likelihood Function for Estimation of the Misclassification Model — loglik","text":"Expected Complete Data Log-Likelihood Function Estimation Misclassification Model","code":""},{"path":"/reference/loglik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected Complete Data Log-Likelihood Function for Estimation of the Misclassification Model — loglik","text":"","code":"loglik(param_current, obs_Y_matrix, X, Z, sample_size, n_cat)"},{"path":"/reference/loglik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected Complete Data Log-Likelihood Function for Estimation of the Misclassification Model — loglik","text":"param_current numeric vector regression parameters, order \\(\\beta, \\gamma\\). \\(\\gamma\\) vector obtained matrix form. matrix form, gamma parameter matrix rows correspond parameters Y* = 1 observed outcome, dimensions Z. matrix form, gamma parameter matrix columns correspond true outcome categories \\(j = 1, \\dots,\\) n_cat. numeric vector gamma_v obtained concatenating gamma matrix, .e. gamma_v <- c(gamma_matrix). obs_Y_matrix numeric matrix indicator variables (0, 1) observed outcome Y*. Rows matrix correspond subject. Columns matrix correspond observed outcome category. row contain exactly one 0 entry exactly one 1 entry. X numeric design matrix true outcome mechanism. Z numeric design matrix observation mechanism. sample_size integer value specifying number observations sample. value equal number rows design matrix, X Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/loglik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected Complete Data Log-Likelihood Function for Estimation of the Misclassification Model — loglik","text":"loglik returns negative value expected log-likelihood function, \\( Q = \\sum_{= 1}^N \\Bigl[ \\sum_{j = 1}^2 w_{ij} \\text{log} \\{ \\pi_{ij} \\} + \\sum_{j = 1}^2 \\sum_{k = 1}^2 w_{ij} y^*_{ik} \\text{log} \\{ \\pi^*_{ikj} \\}\\Bigr]\\), provided inputs.","code":""},{"path":"/reference/loglik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expected Complete Data Log-Likelihood Function for Estimation of the Misclassification Model — loglik","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = true_beta, gamma = true_gamma)  obs_Y_matrix = my_data[[\"obs_Y_matrix\"]] X = my_data[[\"x_design_matrix\"]] Z = my_data[[\"z_design_matrix\"]]  starting_values <- rnorm(6)  loglik_value <- loglik(starting_values,                        obs_Y_matrix = obs_Y_matrix,                        X = X, Z = Z,                        sample_size = n, n_cat = 2) loglik_value }"},{"path":"/reference/mean_pistarjj_compute.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects — mean_pistarjj_compute","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects — mean_pistarjj_compute","text":"Compute Mean Conditional Probability Correct Classification, True Outcome Across Subjects","code":""},{"path":"/reference/mean_pistarjj_compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects — mean_pistarjj_compute","text":"","code":"mean_pistarjj_compute(pistar_matrix, j, sample_size)"},{"path":"/reference/mean_pistarjj_compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects — mean_pistarjj_compute","text":"pistar_matrix numeric matrix conditional probabilities obtained internal function pistar_compute_for_chains. Rows matrix correspond subject observed outcome category. Columns matrix correspond true, latent outcome category. j integer value representing true outcome category compute average conditional probability correct classification . j can take values 1 2. sample_size integer value specifying number observations sample.","code":""},{"path":"/reference/mean_pistarjj_compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects — mean_pistarjj_compute","text":"mean_pistarjj_compute returns numeric value equal average conditional probability \\(P(Y^* = j | Y = j, Z)\\) across subjects.","code":""},{"path":"/reference/mean_pistarjj_compute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects — mean_pistarjj_compute","text":"","code":"if (FALSE) { set.seed(123) n <- 100 ones <- rep(1, n) z <- rnorm(n) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE) gamma <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = FALSE) example_MCMC_chain <- matrix(c(rnorm(n, mean = gamma[1,1]),                                rnorm(n, mean = gamma[2,1]),                                rnorm(n, mean = gamma[1,2]),                                rnorm(n, mean = gamma[2,2])),                              nrow = n, byrow = FALSE) colnames(example_MCMC_chain) <- c(\"gamma[1,1,1]\", \"gamma[1,1,2]\",                                   \"gamma[1,2,1]\", \"gamma[1,2,2]\") chain_colMeans <- colMeans(example_MCMC_chain) conditional_probabilities <- pistar_compute_for_chains(chain_colMeans, Z, n, n_cat = 2) mean_pistarjj_compute(conditional_probabilities, 1, n) mean_pistarjj_compute(conditional_probabilities, 2, n) }"},{"path":"/reference/misclassification_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — misclassification_prob","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — misclassification_prob","text":"Compute conditional probability observing outcome \\(Y^* \\\\{1, 2 \\}\\) given latent true outcome \\(Y \\\\{1, 2 \\}\\) \\(\\frac{\\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}{1 + \\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}\\) \\(= 1, \\dots,\\) n subjects.","code":""},{"path":"/reference/misclassification_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — misclassification_prob","text":"","code":"misclassification_prob(gamma_matrix, z_matrix)"},{"path":"/reference/misclassification_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — misclassification_prob","text":"gamma_matrix numeric matrix estimated regression parameters observation mechanism, Y* | Y (observed outcome, given true outcome) ~ Z (misclassification predictor matrix). Rows matrix correspond parameters Y* = 1 observed outcome, dimensions z_matrix. Columns matrix correspond true outcome categories \\(j = 1, \\dots,\\) n_cat. matrix obtained COMBO_EM COMBO_MCMC. z_matrix numeric matrix covariates observation mechanism. x_matrix contain intercept.","code":""},{"path":"/reference/misclassification_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — misclassification_prob","text":"misclassification_prob returns dataframe containing four columns. first column, Subject, represents subject ID, \\(1\\) n, n sample size, equivalently, number rows z_matrix. second column, Y, represents true, latent outcome category \\(Y \\\\{1, 2 \\}\\). third column, Ystar, represents observed outcome category \\(Y^* \\\\{1, 2 \\}\\). last column, Probability, value equation \\(\\frac{\\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}{1 + \\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}\\) computed subject, observed outcome category, true, latent outcome category.","code":""},{"path":"/reference/misclassification_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — misclassification_prob","text":"","code":"set.seed(123) sample_size <- 1000 cov1 <- rnorm(sample_size) cov2 <- rnorm(sample_size, 1, 2) z_matrix <- matrix(c(cov1, cov2), nrow = sample_size, byrow = FALSE) estimated_gammas <- matrix(c(1, -1, .5, .2, -.6, 1.5), ncol = 2) P_Ystar_Y <- misclassification_prob(estimated_gammas, z_matrix) head(P_Ystar_Y) #>   Subject Y Ystar Probability #> 1       1 1     1   0.7435833 #> 2       2 1     1   0.6660164 #> 3       3 1     1   0.4808373 #> 4       4 1     1   0.7853830 #> 5       5 1     1   0.2352985 #> 6       6 1     1   0.6954044"},{"path":"/reference/model_picker.html","id":null,"dir":"Reference","previous_headings":"","what":"Select a Binary Outcome Misclassification Model for a Given Prior — model_picker","title":"Select a Binary Outcome Misclassification Model for a Given Prior — model_picker","text":"Select Binary Outcome Misclassification Model Given Prior","code":""},{"path":"/reference/model_picker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select a Binary Outcome Misclassification Model for a Given Prior — model_picker","text":"","code":"model_picker(prior)"},{"path":"/reference/model_picker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select a Binary Outcome Misclassification Model for a Given Prior — model_picker","text":"prior character string specifying prior distribution \\(\\beta\\) \\(\\gamma\\) parameters. Options \"t\", \"uniform\", \"normal\", \"dexp\" (double Exponential, Weibull).","code":""},{"path":"/reference/model_picker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select a Binary Outcome Misclassification Model for a Given Prior — model_picker","text":"model_picker returns character string specifying binary outcome misclassification model turned .BUG file used MCMC estimation rjags.","code":""},{"path":"/reference/model_picker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select a Binary Outcome Misclassification Model for a Given Prior — model_picker","text":"","code":"if (FALSE) { t_model <- model_picker(prior = \"t\") }"},{"path":"/reference/naive_jags_picker.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up a Naive Logistic Regression jags.model Object for a Given Prior — naive_jags_picker","title":"Set up a Naive Logistic Regression jags.model Object for a Given Prior — naive_jags_picker","text":"Set Naive Logistic Regression jags.model Object Given Prior","code":""},{"path":"/reference/naive_jags_picker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up a Naive Logistic Regression jags.model Object for a Given Prior — naive_jags_picker","text":"","code":"naive_jags_picker(   prior,   sample_size,   dim_x,   n_cat,   Ystar,   X,   beta_prior_parameters,   number_MCMC_chains,   naive_model_file )"},{"path":"/reference/naive_jags_picker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up a Naive Logistic Regression jags.model Object for a Given Prior — naive_jags_picker","text":"prior character string specifying prior distribution naive \\(\\beta\\) parameters. Options \"t\", \"uniform\", \"normal\", \"dexp\" (double Exponential, Weibull). sample_size integer value specifying number observations sample. dim_x integer specifying number columns design matrix true outcome mechanism, X. n_cat integer specifying number categorical values true outcome, Y, observed outcome, Y* can take. Ystar numeric vector indicator variables (1, 2) observed outcome Y*. reference category 2. X numeric design matrix true outcome mechanism. beta_prior_parameters numeric list prior distribution parameters \\(\\beta\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", first element list contain matrix location, lower bound, mean, shape parameters, respectively, \\(\\beta\\) terms. prior distributions \"t\", \"uniform\", \"normal\", \"dexp\", second element list contain matrix shape, upper bound, standard deviation, scale parameters, respectively, \\(\\beta\\) terms. prior distribution \"t\", third element list contain matrix degrees freedom \\(\\beta\\) terms. third list element empty prior distributions. matrices list dimensions dim_x X n_cat, elements n_cat column set NA. number_MCMC_chains integer specifying number MCMC chains compute. naive_model_file .BUG file used MCMC estimation rjags.","code":""},{"path":"/reference/naive_jags_picker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up a Naive Logistic Regression jags.model Object for a Given Prior — naive_jags_picker","text":"naive_jags_picker returns jags.model object naive logistic regression model predicting potentially misclassified Y* predictor matrix x. object includes specified prior distribution, model, number chains, data.","code":""},{"path":"/reference/naive_jags_picker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up a Naive Logistic Regression jags.model Object for a Given Prior — naive_jags_picker","text":"","code":"if (FALSE) { set.seed(123) n <- 100 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -2), ncol = 1) true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = true_beta, gamma = true_gamma)  obs_Y = my_data[[\"obs_Y\"]] X = my_data[[\"x_design_matrix\"]]  unif_lower_beta <- matrix(c(-5, -5, NA, NA), nrow = 2, byrow = TRUE) unif_upper_beta <- matrix(c(5, 5, NA, NA), nrow = 2, byrow = TRUE)  beta_prior_parameters <- list(lower = unif_lower_beta, upper = unif_upper_beta)  modelstring = naive_model_picker(prior = \"uniform\") temp_model_file = tempfile() tmps = file(temp_model_file, \"w\") cat(modelstring, file = tmps) close(tmps)  jags_model_object <- naive_jags_picker(prior = \"uniform\",                                        sample_size = n,                                        dim_x = ncol(X),                                        n_cat = 2,                                        Ystar = obs_Y, X = X,                                        beta_prior_parameters = beta_prior_parameters,                                        number_MCMC_chains = 1,                                        naive_model_file = temp_model_file) }"},{"path":"/reference/naive_model_picker.html","id":null,"dir":"Reference","previous_headings":"","what":"Select a Logisitic Regression Model for a Given Prior — naive_model_picker","title":"Select a Logisitic Regression Model for a Given Prior — naive_model_picker","text":"Select Logisitic Regression Model Given Prior","code":""},{"path":"/reference/naive_model_picker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select a Logisitic Regression Model for a Given Prior — naive_model_picker","text":"","code":"naive_model_picker(prior)"},{"path":"/reference/naive_model_picker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select a Logisitic Regression Model for a Given Prior — naive_model_picker","text":"prior character string specifying prior distribution naive \\(\\beta\\) parameters. Options \"t\", \"uniform\", \"normal\", \"dexp\" (double Exponential, Weibull).","code":""},{"path":"/reference/naive_model_picker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select a Logisitic Regression Model for a Given Prior — naive_model_picker","text":"naive_model_picker returns character string specifying logistic regression model turned .BUG file used MCMC estimation rjags.","code":""},{"path":"/reference/naive_model_picker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select a Logisitic Regression Model for a Given Prior — naive_model_picker","text":"","code":"if (FALSE) { t_model <- naive_model_picker(prior = \"t\") }"},{"path":"/reference/perfect_sensitivity_EM.html","id":null,"dir":"Reference","previous_headings":"","what":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","text":"EM-Algorithm Estimation Binary Outcome Misclassification Model Assuming Perfect Sensitivity","code":""},{"path":"/reference/perfect_sensitivity_EM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","text":"","code":"perfect_sensitivity_EM(   Ystar,   Z,   X,   start,   beta0_fixed = NULL,   weights = NULL,   expected = TRUE,   tolerance = 1e-07,   max_em_iterations = 1500 )"},{"path":"/reference/perfect_sensitivity_EM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","text":"Ystar numeric vector indicator variables (1, 0) observed outcome Y*. reference category 0. Z numeric matrix covariates true outcome mechanism. Z contain intercept. X numeric matrix covariates observation mechanism. X contain intercept. start Numeric vector starting values parameters true outcome mechanism (\\(\\theta\\)) observation mechanism (\\(\\beta\\)), respectively. beta0_fixed Optional numeric vector values observation mechanism intercept profile . single value entered, corresponds fixing intercept specified value. default NULL. weights Optional vector row-specific weights used selection bias adjustment. default NULL. expected logical value indicating whether calculate covariance matrix via expected Fisher information matrix. default TRUE. tolerance numeric value specifying stop estimation, based difference subsequent log-likelihood estimates. default 1e-7. max_em_iterations integer specifying maximum number iterations EM algorithm. default 1500.","code":""},{"path":"/reference/perfect_sensitivity_EM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","text":"perfect_sensitivity_EM returns list containing nine elements. elements detailed ?SAMBA::obsloglikEM documentation. Code adapted SAMBA::obsloglikEM function.","code":""},{"path":"/reference/perfect_sensitivity_EM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","text":"Beesley, L. Mukherjee, B. (2020). Statistical inference association studies using electronic health records: Handling selection bias outcome misclassification. Biometrics, 78, 214-226.","code":""},{"path":"/reference/perfect_sensitivity_EM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM-Algorithm Estimation of the Binary Outcome Misclassification Model while Assuming Perfect Sensitivity — perfect_sensitivity_EM","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 x_mu <- 0 x_sigma <- 1 z_shape <- 1  true_beta <- matrix(c(1, -.5), ncol = 1) true_gamma <- matrix(c(1, 10, .5, -3), nrow = 2, byrow = FALSE)  my_data <- COMBO_data(sample_size = n,                       x_mu = x_mu, x_sigma = x_sigma,                       z_shape = z_shape,                       beta = true_beta, gamma = true_gamma)  Ystar = ifelse(my_data[[\"obs_Y\"]] == 1, 1, 0) x_matrix = matrix(my_data[[\"x\"]], ncol = 1) z_matrix = matrix(my_data[[\"z\"]], ncol = 1)  starting_values <- rep(1,6) beta_start <- matrix(starting_values[1:2], ncol = 1) gamma_start <- matrix(starting_values[3:4], ncol = 1, nrow = 2, byrow = FALSE)  perfect_sensitivity_results <- perfect_sensitivity_EM(Ystar,                                                       Z = x_matrix, X = z_matrix,                                                       start = c(beta_start, gamma_start),                                                       beta0_fixed = NULL) perfect_sensitivity_results$param }"},{"path":"/reference/pistar_by_chain.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects for each MCMC Chain — pistar_by_chain","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects for each MCMC Chain — pistar_by_chain","text":"Compute Mean Conditional Probability Correct Classification, True Outcome Across Subjects MCMC Chain","code":""},{"path":"/reference/pistar_by_chain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects for each MCMC Chain — pistar_by_chain","text":"","code":"pistar_by_chain(n_chains, chains_list, Z, n, n_cat)"},{"path":"/reference/pistar_by_chain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects for each MCMC Chain — pistar_by_chain","text":"n_chains integer specifying number MCMC chains compute . chains_list numeric list containing samples n_chains MCMC chains. Z numeric design matrix. n integer value specifying number observations sample. value equal number rows design matrix, Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/pistar_by_chain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects for each MCMC Chain — pistar_by_chain","text":"pistar_by_chain returns numeric matrix average conditional probability \\(P(Y^* = j | Y = j, Z)\\) across subjects MCMC chain. Rows matrix correspond MCMC chains, n_chains. first column contains conditional probability \\(P(Y^* = 1 | Y = 1, Z)\\). second column contains conditional probability \\(P(Y^* = 2 | Y = 2, Z)\\).","code":""},{"path":"/reference/pistar_by_chain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the Mean Conditional Probability of Correct Classification, by True Outcome Across all Subjects for each MCMC Chain — pistar_by_chain","text":"","code":"if (FALSE) { set.seed(123) n <- 100 ones <- rep(1, n) z <- rnorm(n) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE) gamma <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = FALSE) example_chain1 <- matrix(c(rnorm(n, mean = gamma[1,1]),                            rnorm(n, mean = gamma[2,1]),                            rnorm(n, mean = gamma[1,2]),                            rnorm(n, mean = gamma[2,2])),                            nrow = n, byrow = FALSE) colnames(example_chain1) <- c(\"gamma[1,1,1]\", \"gamma[1,1,2]\",                               \"gamma[1,2,1]\", \"gamma[1,2,2]\") example_chain2 <- matrix(c(rnorm(n, mean = gamma[1,1]),                            rnorm(n, mean = gamma[2,1]),                            rnorm(n, mean = gamma[1,2]),                            rnorm(n, mean = gamma[2,2])),                            nrow = n, byrow = FALSE) colnames(example_chain2) <- c(\"gamma[1,1,1]\", \"gamma[1,1,2]\",                               \"gamma[1,2,1]\", \"gamma[1,2,2]\") chains_list <- list(example_chain1, example_chain2) pistar_by_chain(n_chains = 2, chains_list = chains_list,                 Z = Z, n = n, n_cat = 2) }"},{"path":"/reference/pistar_compute.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — pistar_compute","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — pistar_compute","text":"Compute Conditional Probability Observed Outcome Given True Outcome, Every Subject","code":""},{"path":"/reference/pistar_compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — pistar_compute","text":"","code":"pistar_compute(gamma, Z, n, n_cat)"},{"path":"/reference/pistar_compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — pistar_compute","text":"gamma numeric matrix regression parameters observed outcome mechanism, Y* | Y (observed outcome, given true outcome) ~ Z (misclassification predictor matrix). Rows matrix correspond parameters Y* = 0 observed outcome, dimensions Z. Columns matrix correspond true outcome categories \\(j = 1, \\dots,\\) n_cat. Z numeric design matrix. n integer value specifying number observations sample. value equal number rows design matrix, Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/pistar_compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — pistar_compute","text":"pistar_compute returns matrix conditional probabilities, \\(P(Y_i^* = k | Y_i = j, Z_i) = \\frac{\\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}{1 + \\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}\\) \\(= 1, \\dots,\\)  n subjects. Rows matrix correspond subject observed outcome. Specifically, probability subject \\(\\) observed category $0$ occurs row \\(\\). probability subject \\(\\) observed category $1$ occurs row \\(+\\)  n. Columns matrix correspond true outcome categories \\(j = 1, \\dots,\\)  n_cat.","code":""},{"path":"/reference/pistar_compute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome, for Every Subject — pistar_compute","text":"","code":"if (FALSE) { set.seed(123) n <- 100 ones <- rep(1, n) z <- rnorm(n) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE) gamma <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = FALSE) conditional_probabilities <- pistar_compute(gamma, Z, n, n_cat = 2) head(conditional_probabilities) }"},{"path":"/reference/pistar_compute_for_chains.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome for a given MCMC Chain, for Every Subject — pistar_compute_for_chains","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome for a given MCMC Chain, for Every Subject — pistar_compute_for_chains","text":"Compute Conditional Probability Observed Outcome Given True Outcome given MCMC Chain, Every Subject","code":""},{"path":"/reference/pistar_compute_for_chains.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome for a given MCMC Chain, for Every Subject — pistar_compute_for_chains","text":"","code":"pistar_compute_for_chains(chain_colMeans, Z, n, n_cat)"},{"path":"/reference/pistar_compute_for_chains.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome for a given MCMC Chain, for Every Subject — pistar_compute_for_chains","text":"chain_colMeans numeric vector containing posterior means sampled parameters given MCMC chain. chain_colMeans must named object (.e. parameter must named gamma[k,j,p]). Z numeric design matrix. n integer value specifying number observations sample. value equal number rows design matrix, Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/pistar_compute_for_chains.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome for a given MCMC Chain, for Every Subject — pistar_compute_for_chains","text":"pistar_compute_for_chains returns matrix conditional probabilities, \\(P(Y_i^* = k | Y_i = j, Z_i) = \\frac{\\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}{1 + \\text{exp}\\{\\gamma_{kj0} + \\gamma_{kjZ} Z_i\\}}\\) \\(= 1, \\dots,\\)  n subjects. Rows matrix correspond subject observed outcome. Specifically, probability subject \\(\\) observed category $0$ occurs row \\(\\). probability subject \\(\\) observed category $1$ occurs row \\(+\\)  n. Columns matrix correspond true outcome categories \\(j = 1, \\dots,\\)  n_cat.","code":""},{"path":"/reference/pistar_compute_for_chains.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Conditional Probability of Each Observed Outcome Given Each True Outcome for a given MCMC Chain, for Every Subject — pistar_compute_for_chains","text":"","code":"if (FALSE) { set.seed(123) n <- 100 ones <- rep(1, n) z <- rnorm(n) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE) gamma <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = FALSE) example_MCMC_chain <- matrix(c(rnorm(n, mean = gamma[1,1]),                                rnorm(n, mean = gamma[2,1]),                                rnorm(n, mean = gamma[1,2]),                                rnorm(n, mean = gamma[2,2])),                              nrow = n, byrow = FALSE) colnames(example_MCMC_chain) <- c(\"gamma[1,1,1]\", \"gamma[1,1,2]\",                                   \"gamma[1,2,1]\", \"gamma[1,2,2]\") chain_colMeans <- colMeans(example_MCMC_chain) conditional_probabilities <- pistar_compute_for_chains(chain_colMeans, Z, n, n_cat = 2) head(conditional_probabilities) }"},{"path":"/reference/pi_compute.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Probability of Each True Outcome, for Every Subject — pi_compute","title":"Compute Probability of Each True Outcome, for Every Subject — pi_compute","text":"Compute Probability True Outcome, Every Subject","code":""},{"path":"/reference/pi_compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Probability of Each True Outcome, for Every Subject — pi_compute","text":"","code":"pi_compute(beta, X, n, n_cat)"},{"path":"/reference/pi_compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Probability of Each True Outcome, for Every Subject — pi_compute","text":"beta numeric column matrix regression parameters Y (true outcome) ~ X (predictor matrix interest). X numeric design matrix. n integer value specifying number observations sample. value equal number rows design matrix, X. n_cat number categorical values true outcome, Y, can take.","code":""},{"path":"/reference/pi_compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Probability of Each True Outcome, for Every Subject — pi_compute","text":"pi_compute returns matrix probabilities, \\(P(Y_i = j | X_i) = \\frac{\\exp(X_i \\beta)}{1 + \\exp(X_i \\beta)}\\) \\(= 1, \\dots,\\)  n subjects. Rows matrix correspond subject. Columns matrix correspond true outcome categories \\(j = 1, \\dots,\\)  n_cat.","code":""},{"path":"/reference/pi_compute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Probability of Each True Outcome, for Every Subject — pi_compute","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 ones <- rep(1, n) x <- rnorm(n) X <- matrix(c(ones, x), nrow = n, byrow = FALSE) beta <- matrix(c(1, 2), ncol = 1) probabilities <- pi_compute(beta, X, n, n_cat = 2) head(probabilities) }"},{"path":"/reference/q_beta_f.html","id":null,"dir":"Reference","previous_headings":"","what":"M-Step Expected Log-Likelihood with respect to Beta — q_beta_f","title":"M-Step Expected Log-Likelihood with respect to Beta — q_beta_f","text":"Objective function form: \\( Q_\\beta = \\sum_{= 1}^N \\Bigl[ \\sum_{j = 0}^1 w_{ij} \\text{log} \\{ \\pi_{ij} \\}\\Bigr]\\). Used obtain estimates \\(\\beta\\) parameters.","code":""},{"path":"/reference/q_beta_f.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"M-Step Expected Log-Likelihood with respect to Beta — q_beta_f","text":"","code":"q_beta_f(beta, X, w_mat, sample_size, n_cat)"},{"path":"/reference/q_beta_f.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"M-Step Expected Log-Likelihood with respect to Beta — q_beta_f","text":"beta numeric vector regression parameters Y (true outcome) ~ X (predictor matrix interest). X numeric design matrix. w_mat Matrix E-step weights obtained w_j. sample_size integer value specifying number observations sample. value equal number rows design matrix, X. n_cat number categorical values true outcome, Y, can take.","code":""},{"path":"/reference/q_beta_f.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"M-Step Expected Log-Likelihood with respect to Beta — q_beta_f","text":"q_beta_f returns negative value expected log-likelihood function, \\( Q_\\beta = \\sum_{= 1}^N \\Bigl[ \\sum_{j = 1}^2 w_{ij} \\text{log} \\{ \\pi_{ij} \\}\\Bigr]\\), provided inputs.","code":""},{"path":"/reference/q_beta_f.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"M-Step Expected Log-Likelihood with respect to Beta — q_beta_f","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 n_cat <- 2  ones <- rep(1, n) x <- rnorm(n) X <- matrix(c(ones, x), nrow = n, byrow = FALSE) z <- rgamma(n, shape = 1) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE)  beta <- matrix(c(1, -2), ncol = 1) gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  probabilities <- pi_compute(beta, X, n, n_cat = 2) conditional_probabilities <- pistar_compute(gamma, Z, n, n_cat = 2)  true_Y <- rep(NA, n) for(i in 1:n){   true_Y[i] = which(rmultinom(1, 1, probabilities[i,]) == 1) } pistar_matrix_labels <- rep(1:n_cat, each = n) obs_Y <- rep(NA, n) for(i in 1:n){  true_j = true_Y[i]  obs_Y[i] = which(rmultinom(1, 1,                             conditional_probabilities[c(i, n + i), true_j]) == 1)  }  obs_Y_reps <- matrix(rep(obs_Y, n_cat), nrow = n, byrow = FALSE) category_matrix <- matrix(rep(1:n_cat, each = n), nrow = n, byrow = FALSE) obs_Y_matrix <- 1 * (obs_Y_reps == category_matrix)  e_step_weights <- w_j(ystar_matrix = obs_Y_matrix,                       pistar_matrix = conditional_probabilities,                       pi_matrix = probabilities,                       sample_size = n, n_cat = n_cat)  start_values <- c(1, 1)  estimate_beta <- optim(par = start_values, fn = q_beta_f,                        X = X, w_mat = e_step_weights,                        sample_size = n, n_cat = n_cat,                        method = \"BFGS\",                        control = list(maxit = 5)) estimate_beta$par  q_beta_f(beta = estimate_beta$par,          X = X, w_mat = e_step_weights,          sample_size = n, n_cat = n_cat) }"},{"path":"/reference/q_gamma_f.html","id":null,"dir":"Reference","previous_headings":"","what":"M-Step Expected Log-Likelihood with respect to Gamma — q_gamma_f","title":"M-Step Expected Log-Likelihood with respect to Gamma — q_gamma_f","text":"Objective function form: \\(Q_{\\gamma} = \\sum_{= 1}^N \\Bigl[\\sum_{j = 1}^2 \\sum_{k = 1}^2 w_{ij} y^*_{ik} \\text{log} \\{ \\pi^*_{ikj} \\}\\Bigr]\\). Used obtain estimates \\(\\gamma\\) parameters.","code":""},{"path":"/reference/q_gamma_f.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"M-Step Expected Log-Likelihood with respect to Gamma — q_gamma_f","text":"","code":"q_gamma_f(gamma_v, Z, obs_Y_matrix, w_mat, sample_size, n_cat)"},{"path":"/reference/q_gamma_f.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"M-Step Expected Log-Likelihood with respect to Gamma — q_gamma_f","text":"gamma_v numeric vector regression parameters observed outcome mechanism, Y* | Y (observed outcome, given true outcome) ~ Z (misclassification predictor matrix). matrix form, gamma parameter matrix rows correspond parameters Y* = 0 observed outcome, dimensions Z. matrix form, gamma parameter matrix columns correspond true outcome categories \\(j = 1, \\dots,\\) n_cat. numeric vector gamma_v obtained concatenating gamma matrix, .e. gamma_v <- c(gamma_matrix). Z numeric design matrix. obs_Y_matrix numeric matrix indicator variables (0, 1) observed outcome Y*. Rows matrix correspond subject. Columns matrix correspond observed outcome category. row contain exactly one 0 entry exactly one 1 entry. w_mat Matrix E-step weights obtained w_j. sample_size integer value specifying number observations sample. value equal number rows design matrix, Z. n_cat number categorical values true outcome, Y, observed outcome, Y* can take.","code":""},{"path":"/reference/q_gamma_f.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"M-Step Expected Log-Likelihood with respect to Gamma — q_gamma_f","text":"q_beta_f returns negative value expected log-likelihood function, \\(Q_{\\gamma} = \\sum_{= 1}^N \\Bigl[\\sum_{j = 1}^2 \\sum_{k = 1}^2 w_{ij} y^*_{ik} \\text{log} \\{ \\pi^*_{ikj} \\}\\Bigr]\\), provided inputs.","code":""},{"path":"/reference/q_gamma_f.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"M-Step Expected Log-Likelihood with respect to Gamma — q_gamma_f","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 n_cat <- 2  ones <- rep(1, n) x <- rnorm(n) X <- matrix(c(ones, x), nrow = n, byrow = FALSE) z <- rgamma(n, shape = 1) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE)  beta <- matrix(c(1, -2), ncol = 1) gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  probabilities <- pi_compute(beta, X, n, n_cat = 2) conditional_probabilities <- pistar_compute(gamma, Z, n, n_cat = 2)  true_Y <- rep(NA, n) for(i in 1:n){   true_Y[i] = which(rmultinom(1, 1, probabilities[i,]) == 1) } pistar_matrix_labels <- rep(1:n_cat, each = n) obs_Y <- rep(NA, n) for(i in 1:n){  true_j = true_Y[i]  obs_Y[i] = which(rmultinom(1, 1,                             conditional_probabilities[c(i, n + i), true_j]) == 1)  }  obs_Y_reps <- matrix(rep(obs_Y, n_cat), nrow = n, byrow = FALSE) category_matrix <- matrix(rep(1:n_cat, each = n), nrow = n, byrow = FALSE) obs_Y_matrix <- 1 * (obs_Y_reps == category_matrix)  e_step_weights <- w_j(ystar_matrix = obs_Y_matrix,                       pistar_matrix = conditional_probabilities,                       pi_matrix = probabilities,                       sample_size = n, n_cat = n_cat)  start_values <- c(1, 1, 1, 1)  estimate_gamma <- optim(par = start_values, fn = q_gamma_f,                         Z = Z, obs_Y_matrix = obs_Y_matrix,                         w_mat = e_step_weights,                         sample_size = n, n_cat = n_cat,                         method = \"BFGS\",                         control = list(maxit = 5)) estimate_gamma$par  q_gamma_f(gamma_v = estimate_gamma$par,           Z = Z, obs_Y_matrix = obs_Y_matrix,           w_mat = e_step_weights,           sample_size = n, n_cat = n_cat) }"},{"path":"/reference/sum_every_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum Every ","title":"Sum Every ","text":"Sum Every \"n\"th Element","code":""},{"path":"/reference/sum_every_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum Every ","text":"","code":"sum_every_n(x, n)"},{"path":"/reference/sum_every_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum Every ","text":"x numeric vector sum n numeric value specifying distance reference index next index summed","code":""},{"path":"/reference/sum_every_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sum Every ","text":"sum_every_n returns vector sums every n^th element vector x.","code":""},{"path":"/reference/sum_every_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sum Every ","text":"","code":"if (FALSE) { x <- c(5, 2, 5, 2, 5, 2) sum_every_n(x, n = 2) }"},{"path":"/reference/sum_every_n1.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum Every ","title":"Sum Every ","text":"Sum Every \"n\"th Element, add 1","code":""},{"path":"/reference/sum_every_n1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum Every ","text":"","code":"sum_every_n1(x, n)"},{"path":"/reference/sum_every_n1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum Every ","text":"x numeric vector sum n numeric value specifying distance reference index next index summed","code":""},{"path":"/reference/sum_every_n1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sum Every ","text":"sum_every_n1 returns vector sums every n^th element vector x, plus 1.","code":""},{"path":"/reference/sum_every_n1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sum Every ","text":"","code":"if (FALSE) { x <- c(5, 2, 5, 2, 5, 2) sum_every_n1(x, n = 2) }"},{"path":"/reference/true_classification_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Probability of Each True Outcome, for Every Subject — true_classification_prob","title":"Compute Probability of Each True Outcome, for Every Subject — true_classification_prob","text":"Compute probability latent true outcome \\(Y \\\\{1, 2 \\}\\) \\(P(Y_i = j | X_i) = \\frac{\\exp(X_i \\beta)}{1 + \\exp(X_i \\beta)}\\) \\(= 1, \\dots,\\) n subjects.","code":""},{"path":"/reference/true_classification_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Probability of Each True Outcome, for Every Subject — true_classification_prob","text":"","code":"true_classification_prob(beta_matrix, x_matrix)"},{"path":"/reference/true_classification_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Probability of Each True Outcome, for Every Subject — true_classification_prob","text":"beta_matrix numeric column matrix estimated regression parameters true outcome mechanism, Y (true outcome) ~ X (predictor matrix interest), obtained COMBO_EM COMBO_MCMC. x_matrix numeric matrix covariates true outcome mechanism. x_matrix contain intercept.","code":""},{"path":"/reference/true_classification_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Probability of Each True Outcome, for Every Subject — true_classification_prob","text":"true_classification_prob returns dataframe containing three columns. first column, Subject, represents subject ID, \\(1\\) n, n sample size, equivalently, number rows x_matrix. second column, Y, represents true, latent outcome category \\(Y \\\\{1, 2 \\}\\). last column, Probability, value equation \\(P(Y_i = j | X_i) = \\frac{\\exp(X_i \\beta)}{1 + \\exp(X_i \\beta)}\\) computed subject true, latent outcome category.","code":""},{"path":"/reference/true_classification_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Probability of Each True Outcome, for Every Subject — true_classification_prob","text":"","code":"set.seed(123) sample_size <- 1000 cov1 <- rnorm(sample_size) cov2 <- rnorm(sample_size, 1, 2) x_matrix <- matrix(c(cov1, cov2), nrow = sample_size, byrow = FALSE) estimated_betas <- matrix(c(1, -1, .5), ncol = 1) P_Y <- true_classification_prob(estimated_betas, x_matrix) head(P_Y) #>   Subject Y Probability #> 1       1 1   0.7435833 #> 2       2 1   0.6660164 #> 3       3 1   0.4808373 #> 4       4 1   0.7853830 #> 5       5 1   0.2352985 #> 6       6 1   0.6954044"},{"path":"/reference/w_j.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute E-step for Binary Outcome Misclassification Model Estimated With the EM-Algorithm — w_j","title":"Compute E-step for Binary Outcome Misclassification Model Estimated With the EM-Algorithm — w_j","text":"Compute E-step Binary Outcome Misclassification Model Estimated EM-Algorithm","code":""},{"path":"/reference/w_j.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute E-step for Binary Outcome Misclassification Model Estimated With the EM-Algorithm — w_j","text":"","code":"w_j(ystar_matrix, pistar_matrix, pi_matrix, sample_size, n_cat)"},{"path":"/reference/w_j.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute E-step for Binary Outcome Misclassification Model Estimated With the EM-Algorithm — w_j","text":"ystar_matrix numeric matrix indicator variables (0, 1) observed outcome Y*. Rows matrix correspond subject. Columns matrix correspond observed outcome category. row contain exactly one 0 entry exactly one 1 entry. pistar_matrix numeric matrix conditional probabilities obtained internal function pistar_compute. Rows matrix correspond subject observed outcome category. Columns matrix correspond true, latent outcome category. pi_matrix numeric matrix probabilities obtained internal function pi_compute. Rows matrix correspond subject. Columns matrix correspond true, latent outcome category. sample_size integer value specifying number observations sample. value equal number rows observed outcome matrix, ystar_matrix. n_cat number categorical values true outcome, Y, observed outcome, Y*, can take.","code":""},{"path":"/reference/w_j.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute E-step for Binary Outcome Misclassification Model Estimated With the EM-Algorithm — w_j","text":"w_j returns matrix E-step weights EM-algorithm, computed follows: \\(\\sum_{k = 1}^2 \\frac{y^*_{ik} \\pi^*_{ikj} \\pi_{ij}}{\\sum_{\\ell = 1}^2 \\pi^*_{\\ell j} \\pi_{ij}}\\). Rows matrix correspond subject. Columns matrix correspond true outcome categories \\(j = 1, \\dots,\\)  n_cat.","code":""},{"path":"/reference/w_j.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute E-step for Binary Outcome Misclassification Model Estimated With the EM-Algorithm — w_j","text":"","code":"if (FALSE) { set.seed(123) n <- 1000 n_cat <- 2  ones <- rep(1, n) x <- rnorm(n) X <- matrix(c(ones, x), nrow = n, byrow = FALSE) z <- rgamma(n, shape = 1) Z <- matrix(c(ones, z), nrow = n, byrow = FALSE)  beta <- matrix(c(1, -2), ncol = 1) gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)  probabilities <- pi_compute(beta, X, n, n_cat = 2) conditional_probabilities <- pistar_compute(gamma, Z, n, n_cat = 2)  true_Y <- rep(NA, n) for(i in 1:n){   true_Y[i] = which(rmultinom(1, 1, probabilities[i,]) == 1) } pistar_matrix_labels <- rep(1:n_cat, each = n) obs_Y <- rep(NA, n) for(i in 1:n){  true_j = true_Y[i]  obs_Y[i] = which(rmultinom(1, 1,                             conditional_probabilities[c(i, n + i), true_j]) == 1)  }  obs_Y_reps <- matrix(rep(obs_Y, n_cat), nrow = n, byrow = FALSE) category_matrix <- matrix(rep(1:n_cat, each = n), nrow = n, byrow = FALSE) obs_Y_matrix <- 1 * (obs_Y_reps == category_matrix)  e_step_weights <- w_j(ystar_matrix = obs_Y_matrix,                       pistar_matrix = conditional_probabilities,                       pi_matrix = probabilities,                       sample_size = n, n_cat = n_cat) head(e_step_weights) }"}]
