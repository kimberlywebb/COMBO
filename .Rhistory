SE = c(SE_EM, sqrt(diag(SAMBA_i$variance)),
sqrt(diag(perfect_sens_i$variance)),
unname(summary(log_reg)$coefficients[,2])),
Convergence = c(rep(results$convergence,
length(c(beta_param_names,
gamma_param_names))),
rep(NA, length(c(SAMBA_beta_param_names,
SAMBA_gamma_param_names))),
rep(NA, length(c(PSens_beta_param_names,
PSens_gamma_param_names))),
rep(log_reg$converged, ncol(X))))
return(estimates)
}
set.seed(123)
n <- 1000
x_mu <- 0
x_sigma <- 1
z_shape <- 1
true_beta <- matrix(c(1, -2), ncol = 1)
true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)
my_data <- COMBO_data(sample_size = n,
x_mu = x_mu, x_sigma = x_sigma,
z_shape = z_shape,
beta = true_beta, gamma = true_gamma)
Ystar = my_data[["obs_Y"]]
x_matrix = matrix(my_data[["x"]], ncol = 1)
z_matrix = matrix(my_data[["z"]], ncol = 1)
starting_values <- rep(1,6)
beta_start <- matrix(starting_values[1:2], ncol = 1)
gamma_start <- matrix(starting_values[3:6], ncol = 2, nrow = 2, byrow = FALSE)
# Major time savings (13s vs. 43s), but slightly different answers than COMBO_EM...
Sys.time()
EM_results2 <- COMBO_EM2(Ystar, x_matrix = x_matrix, z_matrix = z_matrix,
beta_start = beta_start, gamma_start = gamma_start)
Sys.time()
EM_results
EM_results2
pkgdown::build_site()
pkgdown::build_site()
devtools::check()
devtools::check()
pkgdown::build_site()
?COMBO_EM
library(dplyr)
library(tidyr)
library(MASS)
library(Matrix)
library(rjags)
library(turboEM)
library(SAMBA)
function_directory <- "C:/Users/hochsted/Dropbox/Misclassification/Writing/enar_2023/simulation_studies/large_n_v3/functions/"
source_files <- list.files(function_directory, pattern = "*.R")
for (i in 1:length(source_files)) {
source(paste0(function_directory, source_files[i]))
}
save_directory <- "C:/Users/hochsted/Dropbox/Misclassification/Writing/enar_2023/simulation_studies/large_n_v3/"
n_sim <- 1
sample_size <- 100
n_cat <- 2
x_mu <- 0
x_sigma <- 1
z_mu <- 2.5
z_sigma <- 1
mvr_cor <- .30
true_beta <- matrix(c(1, -2), ncol = 1)
true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)
# These settings yield misclassification rates between 5-8%
################################################################################
# Starting values and function settings
starting_values <- rep(1,6)
beta_start <- matrix(starting_values[1:2], ncol = 1)
gamma_start <- matrix(starting_values[3:6], ncol = 2, nrow = 2, byrow = FALSE)
prior <- "uniform"
unif_lower_beta <- matrix(c(-10, -10, NA, NA), nrow = 2, byrow = TRUE)
unif_upper_beta <- matrix(c(10, 10, NA, NA), nrow = 2, byrow = TRUE)
unif_lower_gamma <- array(data = c(-10, NA, -10, NA, -10, NA, -10, NA),
dim = c(2,2,2))
unif_upper_gamma <- array(data = c(10, NA, 10, NA, 10, NA, 10, NA),
dim = c(2,2,2))
beta_prior_parameters <- list(lower = unif_lower_beta, upper = unif_upper_beta)
gamma_prior_parameters <- list(lower = unif_lower_gamma, upper = unif_upper_gamma)
################################################################################
# Run simulations
require(doParallel)
cl <- makeCluster(1)
registerDoParallel(cl)
set.seed(123)
results = foreach(i = 1:n_sim,
.packages = c("MASS", "Matrix", "rjags", "turboEM", "dplyr", "tidyr",
"SAMBA"),
.multicombine = TRUE) %dopar% {
data_i <- generate_data(sample_size, x_mu, x_sigma, z_mu, z_sigma, mvr_cor,
true_beta, true_gamma, n_cat)
classification_prop_table <- prop.table(table(
data_i[["obs_Y"]], data_i[["true_Y"]]),
2)
# EM Estimation
EM_i <- COMBO_EM(data_i[["obs_Y"]],
data_i[["x_matrix"]][,2], data_i[["z_matrix"]][,2],
beta_start = beta_start, gamma_start = gamma_start)
EM_i$Method <- "EM"
EM_i$Stat <- "MLE"
EM_i$Parameter <- c("beta[1,1]", "beta[1,2]",
"gamma[1,1,1]", "gamma[1,1,2]", "gamma[1,2,1]", "gamma[1,2,2]",
"naive_beta[1,1]", "naive_beta[1,2]")
EM_pi <- pi_compute(beta = EM_i$Estimates[1:2],
X = data_i[["x_matrix"]],
n = sample_size, n_cat = 2)
EM_pistar <- pistar_compute(matrix(EM_i$Estimates[3:6],
nrow = 2, byrow = FALSE),
data_i[["z_matrix"]],
n = sample_size, n_cat = 2)
# MCMC Estimation
MCMC_i <- COMBO_MCMC(data_i[["obs_Y"]],
x = data_i[["x_matrix"]][,2], z = data_i[["z_matrix"]][,2],
prior = prior,
beta_prior_parameters = beta_prior_parameters,
gamma_prior_parameters = gamma_prior_parameters,
number_MCMC_chains = 4,
MCMC_sample = 5000, burn_in = 2000)
MCMC_means_i <- rbind(MCMC_i$posterior_means_df[,1:2],
MCMC_i$naive_posterior_means_df[,1:2]) %>%
rename(Estimates = posterior_mean) %>%
rename(Parameter = parameter)
MCMC_means_i$Method <- "MCMC"
MCMC_means_i$Stat <- "Posterior Mean"
MCMC_medians_i <- rbind(MCMC_i$posterior_means_df[,c(1,3)],
MCMC_i$naive_posterior_means_df[,c(1,3)]) %>%
rename(Estimates = posterior_median) %>%
rename(Parameter = parameter)
MCMC_medians_i$Method <- "MCMC"
MCMC_medians_i$Stat <- "Posterior Median"
MCMC_post_i <- rbind(MCMC_means_i, MCMC_medians_i)
MCMC_pi <- pi_compute(beta = MCMC_post_i$Estimates[1:2],
X = data_i[["x_matrix"]],
n = sample_size, n_cat = 2)
MCMC_pistar <- pistar_compute(matrix(MCMC_post_i$Estimates[3:6],
nrow = 2, byrow = TRUE),
data_i[["z_matrix"]],
n = sample_size, n_cat = 2)
results_i <- rbind(EM_i[,c(-3, -4)], MCMC_post_i)
results_i$Sim <- i
flip_Ystar <- ifelse(data_i[["obs_Y"]] == 2, 0, 1)
SAMBA_i <- obsloglikEM(flip_Ystar, Z = data_i[["x_matrix"]][,2],
X = data_i[["z_matrix"]][,2], start = rep(1, 4))
SAMBA_results_i <- data.frame(Parameter = c("beta[1,1]", "beta[1,2]",
"gamma[1,1,1]", "gamma[1,1,2]"),
Estimates = unname(SAMBA_i$param),
Method = "SAMBA EM",
Stat = "MLE",
Sim = i)
perfect_sens_i <- perfect_sensitivity_EM(flip_Ystar, Z = data_i[["x_matrix"]][,2],
X = data_i[["z_matrix"]][,2], start = rep(1, 4))
perfect_sens_results_i <- data.frame(Parameter = c("beta[1,1]", "beta[1,2]",
"gamma[1,2,1]", "gamma[1,2,2]"),
Estimates = unname(perfect_sens_i$param),
Method = "Perfect Sensitivity EM",
Stat = "MLE",
Sim = i)
summary_results_i <- data.frame(Parameter = c("P(Y = 1)", "P(Y = 2)",
"P(Y* = 1)", "P(Y* = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)"),
Estimates = c(length(which(data_i[["true_Y"]] == 1)) / sample_size,
length(which(data_i[["true_Y"]] == 2)) / sample_size,
length(which(data_i[["obs_Y"]] == 1)) / sample_size,
length(which(data_i[["obs_Y"]] == 2)) / sample_size,
classification_prop_table[1, 1],
classification_prop_table[2, 2],
mean(EM_pi[,1]), mean(EM_pi[,2]),
mean(EM_pistar[1:sample_size, 1]),
mean(EM_pistar[(sample_size + 1):(2 * sample_size), 2]),
mean(MCMC_pi[,1]), mean(MCMC_pi[,2]),
mean(MCMC_pistar[1:sample_size, 1]),
mean(MCMC_pistar[(sample_size + 1):(2 * sample_size), 2])),
Method = c(rep("Data", 6),
rep("EM", 4),
rep("MCMC", 4)),
Stat = c("P(Y = 1)", "P(Y = 2)",
"P(Y* = 1)", "P(Y* = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)"),
Sim = i)
results_to_return = do.call("rbind", list(results_i, SAMBA_results_i,
perfect_sens_results_i,
summary_results_i))
return(results_to_return)
}
library(dplyr)
library(tidyr)
library(MASS)
library(Matrix)
library(rjags)
library(turboEM)
library(SAMBA)
function_directory <- "C:/Users/hochsted/Dropbox/Misclassification/Writing/enar_2023/simulation_studies/large_n_v3/functions/"
source_files <- list.files(function_directory, pattern = "*.R")
for (i in 1:length(source_files)) {
source(paste0(function_directory, source_files[i]))
}
save_directory <- "C:/Users/hochsted/Dropbox/Misclassification/Writing/enar_2023/simulation_studies/large_n_v3/"
n_sim <- 1
sample_size <- 100
n_cat <- 2
x_mu <- 0
x_sigma <- 1
z_mu <- 2.5
z_sigma <- 1
mvr_cor <- .30
true_beta <- matrix(c(1, -2), ncol = 1)
true_gamma <- matrix(c(.5, 1, -.5, -1), nrow = 2, byrow = FALSE)
# These settings yield misclassification rates between 5-8%
################################################################################
# Starting values and function settings
starting_values <- rep(1,6)
beta_start <- matrix(starting_values[1:2], ncol = 1)
gamma_start <- matrix(starting_values[3:6], ncol = 2, nrow = 2, byrow = FALSE)
prior <- "uniform"
unif_lower_beta <- matrix(c(-10, -10, NA, NA), nrow = 2, byrow = TRUE)
unif_upper_beta <- matrix(c(10, 10, NA, NA), nrow = 2, byrow = TRUE)
unif_lower_gamma <- array(data = c(-10, NA, -10, NA, -10, NA, -10, NA),
dim = c(2,2,2))
unif_upper_gamma <- array(data = c(10, NA, 10, NA, 10, NA, 10, NA),
dim = c(2,2,2))
beta_prior_parameters <- list(lower = unif_lower_beta, upper = unif_upper_beta)
gamma_prior_parameters <- list(lower = unif_lower_gamma, upper = unif_upper_gamma)
################################################################################
# Run simulations
require(doParallel)
cl <- makeCluster(1)
registerDoParallel(cl)
set.seed(123)
results = foreach(i = 1:n_sim,
.packages = c("MASS", "Matrix", "rjags", "turboEM", "dplyr", "tidyr",
"SAMBA"),
.multicombine = TRUE) %dopar% {
data_i <- generate_data(sample_size, x_mu, x_sigma, z_mu, z_sigma, mvr_cor,
true_beta, true_gamma, n_cat)
classification_prop_table <- prop.table(table(
data_i[["obs_Y"]], data_i[["true_Y"]]),
2)
# EM Estimation
EM_i <- COMBO_EM(data_i[["obs_Y"]],
data_i[["x_matrix"]][,2], data_i[["z_matrix"]][,2],
beta_start = beta_start, gamma_start = gamma_start)
EM_i$Method <- "EM"
EM_i$Stat <- "MLE"
EM_i$Parameter <- c("beta[1,1]", "beta[1,2]",
"gamma[1,1,1]", "gamma[1,1,2]", "gamma[1,2,1]", "gamma[1,2,2]",
"naive_beta[1,1]", "naive_beta[1,2]")
EM_pi <- pi_compute(beta = EM_i$Estimates[1:2],
X = data_i[["x_matrix"]],
n = sample_size, n_cat = 2)
EM_pistar <- pistar_compute(matrix(EM_i$Estimates[3:6],
nrow = 2, byrow = FALSE),
data_i[["z_matrix"]],
n = sample_size, n_cat = 2)
# MCMC Estimation
MCMC_i <- COMBO_MCMC(data_i[["obs_Y"]],
x = data_i[["x_matrix"]][,2], z = data_i[["z_matrix"]][,2],
prior = prior,
beta_prior_parameters = beta_prior_parameters,
gamma_prior_parameters = gamma_prior_parameters,
number_MCMC_chains = 4,
MCMC_sample = 5000, burn_in = 2000)
MCMC_means_i <- rbind(MCMC_i$posterior_means_df[,1:2],
MCMC_i$naive_posterior_means_df[,1:2]) %>%
rename(Estimates = posterior_mean) %>%
rename(Parameter = parameter)
MCMC_means_i$Method <- "MCMC"
MCMC_means_i$Stat <- "Posterior Mean"
MCMC_medians_i <- rbind(MCMC_i$posterior_means_df[,c(1,3)],
MCMC_i$naive_posterior_means_df[,c(1,3)]) %>%
rename(Estimates = posterior_median) %>%
rename(Parameter = parameter)
MCMC_medians_i$Method <- "MCMC"
MCMC_medians_i$Stat <- "Posterior Median"
MCMC_post_i <- rbind(MCMC_means_i, MCMC_medians_i)
MCMC_pi <- pi_compute(beta = MCMC_post_i$Estimates[1:2],
X = data_i[["x_matrix"]],
n = sample_size, n_cat = 2)
MCMC_pistar <- pistar_compute(matrix(MCMC_post_i$Estimates[3:6],
nrow = 2, byrow = TRUE),
data_i[["z_matrix"]],
n = sample_size, n_cat = 2)
results_i <- rbind(EM_i[,c(-3, -4)], MCMC_post_i)
results_i$Sim <- i
flip_Ystar <- ifelse(data_i[["obs_Y"]] == 2, 0, 1)
SAMBA_i <- obsloglikEM(flip_Ystar, Z = data_i[["x_matrix"]][,2],
X = data_i[["z_matrix"]][,2], start = rep(1, 4))
SAMBA_results_i <- data.frame(Parameter = c("beta[1,1]", "beta[1,2]",
"gamma[1,1,1]", "gamma[1,1,2]"),
Estimates = unname(SAMBA_i$param),
Method = "SAMBA EM",
Stat = "MLE",
Sim = i)
perfect_sens_i <- perfect_sensitivity_EM(flip_Ystar, Z = data_i[["x_matrix"]][,2],
X = data_i[["z_matrix"]][,2], start = rep(1, 4))
perfect_sens_results_i <- data.frame(Parameter = c("beta[1,1]", "beta[1,2]",
"gamma[1,2,1]", "gamma[1,2,2]"),
Estimates = unname(perfect_sens_i$param),
Method = "Perfect Sensitivity EM",
Stat = "MLE",
Sim = i)
summary_results_i <- data.frame(Parameter = c("P(Y = 1)", "P(Y = 2)",
"P(Y* = 1)", "P(Y* = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)"),
Estimates = c(length(which(data_i[["true_Y"]] == 1)) / sample_size,
length(which(data_i[["true_Y"]] == 2)) / sample_size,
length(which(data_i[["obs_Y"]] == 1)) / sample_size,
length(which(data_i[["obs_Y"]] == 2)) / sample_size,
classification_prop_table[1, 1],
classification_prop_table[2, 2],
mean(EM_pi[,1]), mean(EM_pi[,2]),
mean(EM_pistar[1:sample_size, 1]),
mean(EM_pistar[(sample_size + 1):(2 * sample_size), 2]),
mean(MCMC_pi[,1]), mean(MCMC_pi[,2]),
mean(MCMC_pistar[1:sample_size, 1]),
mean(MCMC_pistar[(sample_size + 1):(2 * sample_size), 2])),
Method = c(rep("Data", 6),
rep("EM", 4),
rep("MCMC", 4)),
Stat = c("P(Y = 1)", "P(Y = 2)",
"P(Y* = 1)", "P(Y* = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)",
"P(Y = 1)", "P(Y = 2)",
"P(Y* = 1 | Y = 1)",
"P(Y* = 2 | Y = 2)"),
Sim = i)
results_to_return = do.call("rbind", list(results_i, SAMBA_results_i,
perfect_sens_results_i,
summary_results_i))
return(results_to_return)
}
stopCluster(cl)
results
data_i <- generate_data(sample_size, x_mu, x_sigma, z_mu, z_sigma, mvr_cor,
true_beta, true_gamma, n_cat)
classification_prop_table <- prop.table(table(
data_i[["obs_Y"]], data_i[["true_Y"]]),
2)
classification_prop_table
data_i <- generate_data(sample_size, x_mu, x_sigma, z_mu, z_sigma, mvr_cor,
true_beta, true_gamma, n_cat)
classification_prop_table <- prop.table(table(
data_i[["obs_Y"]], data_i[["true_Y"]]),
2)
classification_prop_table
sample_size <- 10000
data_i <- generate_data(sample_size, x_mu, x_sigma, z_mu, z_sigma, mvr_cor,
true_beta, true_gamma, n_cat)
classification_prop_table <- prop.table(table(
data_i[["obs_Y"]], data_i[["true_Y"]]),
2)
classification_prop_table
#' Ystar = my_data[["obs_Y"]]
#' x_matrix = matrix(my_data[["x"]], ncol = 1)
#' z_matrix = matrix(my_data[["z"]], ncol = 1)
#'
#' starting_values <- rep(1,6)
#' beta_start <- matrix(starting_values[1:2], ncol = 1)
#' gamma_start <- matrix(starting_values[3:6], ncol = 2, nrow = 2, byrow = FALSE)
#'
#' EM_results <- COMBO_EM(Ystar, x_matrix = x_matrix, z_matrix = z_matrix,
#'                        beta_start = beta_start, gamma_start = gamma_start)
COMBO_EM <- function(Ystar,
x_matrix, z_matrix,
beta_start, gamma_start,
tolerance = 1e-7, max_em_iterations = 1500,
em_method = "squarem"){
if (is.data.frame(z_matrix))
z_matrix <- as.matrix(z_matrix)
if (!is.numeric(z_matrix))
stop("'z_matrix' should be a numeric matrix.")
if (is.vector(z_matrix))
z_matrix <- as.matrix(z_matrix)
if (!is.matrix(z_matrix))
stop("'z_matrix' should be a matrix or data.frame.")
if (!is.null(x_matrix)) {
if (is.data.frame(x_matrix))
x_matrix <- as.matrix(x_matrix)
if (!is.numeric(x_matrix))
stop("'x_matrix' must be numeric.")
if (is.vector(x_matrix))
x_matrix <- as.matrix(x_matrix)
if (!is.matrix(x_matrix))
stop("'x_matrix' must be a data.frame or matrix.")
}
if (!is.numeric(Ystar) || !is.vector(Ystar))
stop("'Ystar' must be a numeric vector.")
if (length(setdiff(1:2, unique(Ystar))) != 0)
stop("'Ystar' must be coded 1/2, where the reference category is 2.")
n_cat = 2
sample_size = length(Ystar)
if (nrow(z_matrix) != sample_size)
stop("The number of rows of 'z_matrix' must match the length of 'Ystar'.")
if (!is.null(x_matrix) && nrow(x_matrix) != sample_size)
stop("The number of rows of 'x_matrix' must match the length of 'Ystar'.")
X = matrix(c(rep(1, sample_size), c(x_matrix)),
byrow = FALSE, nrow = sample_size)
Z = matrix(c(rep(1, sample_size), c(z_matrix)),
byrow = FALSE, nrow = sample_size)
obs_Y_reps = matrix(rep(Ystar, n_cat), nrow = sample_size, byrow = FALSE)
category_matrix = matrix(rep(1:n_cat, each = sample_size), nrow = sample_size,
byrow = FALSE)
obs_Y_matrix = 1 * (obs_Y_reps == category_matrix)
control_settings = list(convtype = "parameter", tol = tolerance,
stoptype = "maxiter", maxiter = max_em_iterations)
results = turboEM::turboem(par = c(c(beta_start), c(gamma_start)),
fixptfn = em_function, objfn = loglik,
method = c(em_method),
obs_Y_matrix = obs_Y_matrix,
X = X, Z = Z,
sample_size = sample_size, n_cat = n_cat,
control.run = control_settings)
Ystar01 = ifelse(Ystar == 1, 1, ifelse(Ystar == 2, 0, NA))
log_reg = stats::glm(Ystar01 ~ . + 0, as.data.frame(X),
family = "binomial"(link = "logit"))
SAMBA_start <- c(beta_start, c(gamma_start)[1:(1 + ncol(z_matrix))])
SAMBA_i <- SAMBA::obsloglikEM(Ystar01, Z = x_matrix,
X = z_matrix, start = SAMBA_start,
tol = tolerance,
maxit = max_em_iterations)
perfect_sens_start <- c(beta_start, c(gamma_start)[(2 + ncol(z_matrix)):length(c(gamma_start))])
perfect_sens_i <- perfect_sensitivity_EM(Ystar01, Z = x_matrix,
X = z_matrix, start = perfect_sens_start,
tolerance = tolerance,
max_em_iterations = max_em_iterations)
# Do label switching correction within the EM algorithm simulation
results_i_gamma <- matrix(turboEM::pars(results)[(ncol(X) + 1):(ncol(X) + (n_cat * ncol(Z)))],
ncol = n_cat, byrow = FALSE)
results_i_pistar_v <- pistar_compute(results_i_gamma, Z, sample_size, n_cat)
pistar_11 <- mean(results_i_pistar_v[1:sample_size, 1])
pistar_22 <- mean(results_i_pistar_v[(sample_size + 1):(2*sample_size), 2])
estimates_i <- if ((pistar_11 > .50 | pistar_22 > .50) |
(is.na(pistar_11) & is.na(pistar_22))) {
# If turboem cannot estimate the parameters they will be NA.
turboEM::pars(results)
} else {
gamma_index = (ncol(X) + 1):(ncol(X) + (n_cat * ncol(Z)))
n_gamma_param = length(gamma_index) / n_cat
gamma_flip_index = ncol(X) + c((n_gamma_param + 1):length(gamma_index), 1:n_gamma_param)
c(-1*turboEM::pars(results)[1:ncol(X)], turboEM::pars(results)[gamma_flip_index])
}
sigma_EM = tryCatch(solve(turboEM::hessian(results)[[1]]), silent = TRUE,
error = function(e) NA)
SE_EM = tryCatch(sqrt(diag(Matrix::nearPD(sigma_EM)$mat)),
silent = TRUE,
error = function(e) rep(NA, ncol(X) + (n_cat * ncol(Z))))
beta_param_names <- paste0(rep("beta", ncol(X)), 1:ncol(X))
gamma_param_names <- paste0(rep("gamma", (n_cat * ncol(Z))),
rep(1:ncol(Z), n_cat),
rep(1:n_cat, each = ncol(Z)))
SAMBA_beta_param_names <- paste0(rep("SAMBA_beta", ncol(X)), 1:ncol(X))
SAMBA_gamma_param_names <- paste0(rep("SAMBA_gamma", (ncol(Z))),
rep(1:ncol(Z), 1),
rep(1, ncol(Z)))
PSens_beta_param_names <- paste0(rep("PSens_beta", ncol(X)), 1:ncol(X))
PSens_gamma_param_names <- paste0(rep("PSens_gamma", (ncol(Z))),
rep(1:ncol(Z), 1),
rep(2, ncol(Z)))
naive_beta_param_names <- paste0("naive_", beta_param_names)
estimates <- data.frame(Parameter = c(beta_param_names,
gamma_param_names,
SAMBA_beta_param_names,
SAMBA_gamma_param_names,
PSens_beta_param_names,
PSens_gamma_param_names,
naive_beta_param_names),
Estimates = c(estimates_i,
unname(SAMBA_i$param),
unname(perfect_sens_i$param),
unname(log_reg$coefficients)),
SE = c(SE_EM, sqrt(diag(SAMBA_i$variance)),
sqrt(diag(perfect_sens_i$variance)),
unname(summary(log_reg)$coefficients[,2])),
Convergence = c(rep(results$convergence,
length(c(beta_param_names,
gamma_param_names))),
rep(NA, length(c(SAMBA_beta_param_names,
SAMBA_gamma_param_names))),
rep(NA, length(c(PSens_beta_param_names,
PSens_gamma_param_names))),
rep(log_reg$converged, ncol(X))))
return(estimates)
}
rm(COMBO_EM())
rm(COMBO_EM
)
